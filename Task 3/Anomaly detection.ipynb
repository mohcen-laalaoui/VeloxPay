{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b47c7a-a2d4-4d2a-92fd-2e34b5088d7a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d60751-747a-482b-8c09-1863d46f084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from flask import Flask, request, jsonify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a834ff-5c3b-4930-810e-1d2d00c9373b",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca847d0f-7014-4c6a-b095-0eb72a7738ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, numerical_cols=None, categorical_cols=None, target=None):\n",
    "    data = df.copy()\n",
    "    data = handle_missing_values(data)\n",
    "    \n",
    "    if categorical_cols:\n",
    "        data = encode_categorical_features(data, categorical_cols)\n",
    "    \n",
    "    if numerical_cols is None:\n",
    "        numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
    "    \n",
    "    if target:\n",
    "        X = data.drop(target, axis=1).values\n",
    "        y = data[target].values\n",
    "        return X, y, scaler\n",
    "    else:\n",
    "        X = data.values\n",
    "        return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71263a60-f70c-4a09-a49f-6e4db3265e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in num_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "    \n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be069100-1cf0-46e9-93b5-10ef0ba0316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(df, categorical_cols):\n",
    "    for col in categorical_cols:\n",
    "        df = pd.get_dummies(df, columns=[col], drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29476b1-4cd2-4c44-8509-3b3466c11f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_isolation_forest(X, contamination=0.1, random_state=42):\n",
    "    model = IsolationForest(\n",
    "        contamination=contamination,\n",
    "        random_state=random_state,\n",
    "        n_estimators=100,\n",
    "        max_samples='auto'\n",
    "    )\n",
    "    model.fit(X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc9585-49ff-4105-81e6-05d7621630f2",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "679ea735-b1c8-4d82-839f-6b46437a6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_anomaly_detection(y_true, y_pred, verbose=True):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='binary', pos_label=1\n",
    "    )\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac8c540b-0a6c-4cd5-a8ff-3c1594c8d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsolationForestSystem:\n",
    "    def __init__(self, contamination=0.1, random_state=42):\n",
    "        self.contamination = contamination\n",
    "        self.random_state = random_state\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def fit(self, X, feature_names=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.feature_names = X.columns.tolist()\n",
    "            X_values = X.values\n",
    "        else:\n",
    "            self.feature_names = feature_names\n",
    "            X_values = X\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X_values)\n",
    "        \n",
    "        self.model = IsolationForest(\n",
    "            contamination=self.contamination,\n",
    "            random_state=self.random_state,\n",
    "            n_estimators=100,\n",
    "            max_samples='auto'\n",
    "        )\n",
    "        self.model.fit(X_scaled)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_values = X.values\n",
    "        else:\n",
    "            X_values = X\n",
    "        \n",
    "        X_scaled = self.scaler.transform(X_values)\n",
    "        \n",
    "        anomaly_scores = self.model.decision_function(X_scaled)\n",
    "        predictions = self.model.predict(X_scaled)\n",
    "        y_pred = np.where(predictions == -1, 1, 0)\n",
    "        \n",
    "        return y_pred, anomaly_scores\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        import joblib\n",
    "        \n",
    "        model_data = {\n",
    "            'model': self.model,\n",
    "            'scaler': self.scaler,\n",
    "            'feature_names': self.feature_names,\n",
    "            'contamination': self.contamination,\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "        \n",
    "        joblib.dump(model_data, filepath)\n",
    "        print(f\"Model saved to {filepath}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, filepath):\n",
    "        import joblib\n",
    "        \n",
    "        model_data = joblib.load(filepath)\n",
    "        \n",
    "        instance = cls(\n",
    "            contamination=model_data['contamination'],\n",
    "            random_state=model_data['random_state']\n",
    "        )\n",
    "        instance.model = model_data['model']\n",
    "        instance.scaler = model_data['scaler']\n",
    "        instance.feature_names = model_data['feature_names']\n",
    "        \n",
    "        return instance\n",
    "    \n",
    "    def explain_predictions(self, X, n_top_features=3):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            if self.feature_names is None:\n",
    "                raise ValueError(\"Feature names must be provided for explanation\")\n",
    "            X = pd.DataFrame(X, columns=self.feature_names)\n",
    "        \n",
    "        y_pred, anomaly_scores = self.predict(X)\n",
    "        \n",
    "        explanations = {}\n",
    "        anomaly_indices = np.where(y_pred == 1)[0]\n",
    "        \n",
    "        for idx in anomaly_indices:\n",
    "            sample = X.iloc[idx]\n",
    "            scaled_sample = self.scaler.transform(sample.values.reshape(1, -1))[0]\n",
    "            \n",
    "            feature_contribs = []\n",
    "            for i, (feature, value) in enumerate(zip(X.columns, scaled_sample)):\n",
    "                contribution = abs(value)\n",
    "                feature_contribs.append((feature, contribution, sample[feature]))\n",
    "            \n",
    "            feature_contribs.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_features = feature_contribs[:n_top_features]\n",
    "            \n",
    "            explanations[idx] = {\n",
    "                'anomaly_score': anomaly_scores[idx],\n",
    "                'top_contributing_features': top_features\n",
    "            }\n",
    "        \n",
    "        return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "940aa411-0fd5-454a-96dc-357da1a107cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyMonitoringService:\n",
    "    def __init__(self, model_path=None, model=None):\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "        elif model_path is not None:\n",
    "            self.model = IsolationForestSystem.load_model(model_path)\n",
    "        else:\n",
    "            raise ValueError(\"Either model or model_path must be provided\")\n",
    "        \n",
    "        self.alert_threshold = 0.9\n",
    "        self.anomalies_detected = []\n",
    "        self.last_check_time = None\n",
    "    \n",
    "    def check_data(self, new_data):\n",
    "        import time\n",
    "        self.last_check_time = time.time()\n",
    "        \n",
    "        y_pred, anomaly_scores = self.model.predict(new_data)\n",
    "        anomaly_indices = np.where(y_pred == 1)[0]\n",
    "        \n",
    "        if len(anomaly_indices) > 0:\n",
    "            explanations = self.model.explain_predictions(new_data)\n",
    "            \n",
    "            for idx in anomaly_indices:\n",
    "                anomaly_data = {\n",
    "                    'timestamp': self.last_check_time,\n",
    "                    'index': idx,\n",
    "                    'data': new_data.iloc[idx].to_dict() if isinstance(new_data, pd.DataFrame) else dict(zip(self.model.feature_names, new_data[idx])),\n",
    "                    'anomaly_score': anomaly_scores[idx],\n",
    "                    'explanation': explanations.get(idx)\n",
    "                }\n",
    "                self.anomalies_detected.append(anomaly_data)\n",
    "                \n",
    "                if anomaly_scores[idx] > self.alert_threshold:\n",
    "                    self._send_alert(anomaly_data)\n",
    "        \n",
    "        return [self.anomalies_detected[i] for i in range(len(self.anomalies_detected) - len(anomaly_indices), len(self.anomalies_detected))]\n",
    "    \n",
    "    def _send_alert(self, anomaly_data):\n",
    "        print(f\"ALERT: Critical anomaly detected!\")\n",
    "        print(f\"Anomaly score: {anomaly_data['anomaly_score']:.4f}\")\n",
    "        print(\"Data:\", anomaly_data['data'])\n",
    "        if anomaly_data['explanation']:\n",
    "            print(\"Contributing factors:\")\n",
    "            for feature, contribution, value in anomaly_data['explanation']['top_contributing_features']:\n",
    "                print(f\"  - {feature}: Value = {value}, Contribution = {contribution:.4f}\")\n",
    "    \n",
    "    def get_anomaly_history(self, start_time=None, end_time=None):\n",
    "        if not self.anomalies_detected:\n",
    "            return []\n",
    "        \n",
    "        if start_time is None and end_time is None:\n",
    "            return self.anomalies_detected\n",
    "        \n",
    "        filtered_anomalies = []\n",
    "        for anomaly in self.anomalies_detected:\n",
    "            timestamp = anomaly['timestamp']\n",
    "            if start_time and timestamp < start_time:\n",
    "                continue\n",
    "            if end_time and timestamp > end_time:\n",
    "                continue\n",
    "            filtered_anomalies.append(anomaly)\n",
    "        \n",
    "        return filtered_anomalies\n",
    "    \n",
    "    def set_alert_threshold(self, threshold):\n",
    "        if 0 <= threshold <= 1:\n",
    "            self.alert_threshold = threshold\n",
    "        else:\n",
    "            raise ValueError(\"Threshold must be between 0 and 1\")\n",
    "    \n",
    "    def clear_history(self):\n",
    "        self.anomalies_detected = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb93b2-d814-47fc-b99b-86a92ad4693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flask_api(model_path):    \n",
    "    app = Flask(__name__)\n",
    "    monitoring_service = AnomalyMonitoringService(model_path=model_path)\n",
    "    \n",
    "    @app.route('/predict', methods=['POST'])\n",
    "    def predict():\n",
    "        try:\n",
    "            data = request.json\n",
    "            df = pd.DataFrame(data['data'])\n",
    "            \n",
    "            y_pred, anomaly_scores = monitoring_service.model.predict(df)\n",
    "            \n",
    "            result = {\n",
    "                'predictions': y_pred.tolist(),\n",
    "                'anomaly_scores': anomaly_scores.tolist(),\n",
    "                'anomaly_indices': np.where(y_pred == 1)[0].tolist()\n",
    "            }\n",
    "            \n",
    "            if np.sum(y_pred) > 0:\n",
    "                explanations = monitoring_service.model.explain_predictions(df)\n",
    "                result['explanations'] = {\n",
    "                    str(idx): {\n",
    "                        'anomaly_score': float(explanations[idx]['anomaly_score']),\n",
    "                        'contributing_features': [\n",
    "                            {\n",
    "                                'feature': str(feature),\n",
    "                                'contribution': float(contribution),\n",
    "                                'value': float(value)\n",
    "                            }\n",
    "                            for feature, contribution, value in explanations[idx]['top_contributing_features']\n",
    "                        ]\n",
    "                    }\n",
    "                    for idx in explanations\n",
    "                }\n",
    "            \n",
    "            return jsonify(result)\n",
    "        \n",
    "        except Exception as e:\n",
    "            return jsonify({'error': str(e)}), 400\n",
    "    \n",
    "    @app.route('/monitor', methods=['POST'])\n",
    "    def monitor():\n",
    "        try:\n",
    "            data = request.json\n",
    "            df = pd.DataFrame(data['data'])\n",
    "            \n",
    "            anomalies = monitoring_service.check_data(df)\n",
    "            \n",
    "            result = {\n",
    "                'anomalies_detected': len(anomalies),\n",
    "                'anomalies': [\n",
    "                    {\n",
    "                        'index': anomaly['index'],\n",
    "                        'anomaly_score': float(anomaly['anomaly_score']),\n",
    "                        'timestamp': anomaly['timestamp']\n",
    "                    }\n",
    "                    for anomaly in anomalies\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            return jsonify(result)\n",
    "        \n",
    "        except Exception as e:\n",
    "            return jsonify({'error': str(e)}), 400\n",
    "    \n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae5a298-6c7e-4b54-89aa-4859f731df64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
